{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatened_json_files(path):\n",
    "    directory_path = path\n",
    "    concatenated_file = []\n",
    "    file_counter = 0\n",
    "\n",
    "    file_list = [f for f in listdir(directory_path) if isfile(join(directory_path, f))]\n",
    "\n",
    "    for file in file_list:\n",
    "        file_counter+=1\n",
    "        with open(f'{directory_path}{file}') as f:\n",
    "            for obj in json.load(f):\n",
    "                concatenated_file.append(obj)\n",
    "    \n",
    "    print(f'Concatened {file_counter} json files into one.')\n",
    "    return concatenated_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experienced-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatened 517 json files into one.\n"
     ]
    }
   ],
   "source": [
    "df = pd.json_normalize(concatened_json_files('../datasets/anime/raw_data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "solid-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_treatment = ['Score','Ranked','Popularity','ScoredBy','Members','Favorites']\n",
    "\n",
    "for column in columns_for_treatment:\n",
    "    def transform_into_number(df_row):\n",
    "        if df_row[f'details.{column}'] == 'N/A' or df_row[f'details.{column}'] == '':\n",
    "            return 0\n",
    "        if '.' in df_row[f'details.{column}']:\n",
    "            return float(df_row[f'details.{column}'])\n",
    "        return int(df_row[f'details.{column}'].replace('#','').replace(',',''))\n",
    "    df[f'details.{column}'] = df.apply(transform_into_number,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "religious-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_treatment = ['Producers','Licensors','Studios']\n",
    "\n",
    "for column in columns_for_treatment:\n",
    "    def treat_blank_values(df_row):\n",
    "        if 'add some' in df_row[f'details.{column}'] or 'None found' in df_row[f'details.{column}']:\n",
    "            return None\n",
    "        else:\n",
    "            return df_row[f'details.{column}']\n",
    "    df[f'details.{column}'] = df.apply(treat_blank_values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_format(date):\n",
    "    try:\n",
    "        date_transformed = datetime.strptime(date, \"%b %d, %Y\")\n",
    "        return datetime.strftime(date_transformed, '%Y-%m-%d')\n",
    "    except:\n",
    "        return f'Failed: {date}'\n",
    "\n",
    "    \n",
    "def get_aired_from_date(df_row):\n",
    "    if df_row['details.Aired'] == 'Not available':\n",
    "        return None\n",
    "    if len(df_row['details.Aired']) == 4:\n",
    "        return convert_date_format(f'Jan 1, {df_row[\"details.Aired\"]}')\n",
    "    if df_row['details.Status'] == 'Not yet aired':\n",
    "        return None\n",
    "    else:\n",
    "        aired = df_row['details.Aired'][:12].rstrip()\n",
    "        \n",
    "        if 'to ?' in aired and len(aired) == 9:\n",
    "            return convert_date_format(f'Jan 1, {aired[:4]}')\n",
    "        \n",
    "        if 'to' not in aired and len(aired) == 9:\n",
    "            partial_date = aired.rstrip().lstrip()\n",
    "            return convert_date_format(f'{partial_date[:3]} 1, {partial_date[5:]}')\n",
    "        \n",
    "        elif 'to' in aired:\n",
    "            if len(aired) == 9:\n",
    "                partial_date = aired.replace('to','').rstrip().lstrip()\n",
    "                return convert_date_format(f'{partial_date[:3]} 1, {partial_date[5:]}')\n",
    "            if len(aired[:aired.find('to')-1].rstrip()) == 4:\n",
    "                return convert_date_format(f'Jan 1, {aired[:aired.find(\"to\")-1].rstrip()}')\n",
    "            \n",
    "        else:\n",
    "            return convert_date_format(aired)\n",
    "\n",
    "\n",
    "def get_aired_to_date(df_row):\n",
    "    if df_row['details.Aired'] == 'Not available':\n",
    "        return None\n",
    "    if len(df_row['details.Aired']) == 4:\n",
    "        return convert_date_format(f'Jan 1, {df_row[\"details.Aired\"]}')\n",
    "    if 'to ?' in df_row['details.Aired']:\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        aired = df_row['details.Aired'][-12:].lstrip()\n",
    "\n",
    "        if len(aired) == 9:\n",
    "            partial_date = aired.replace('to','').rstrip().lstrip()\n",
    "            return convert_date_format(f'{partial_date[:3]} 1, {partial_date[5:]}')\n",
    "\n",
    "        if 'to' in aired:\n",
    "            if len(aired[aired.find('to')+3:]) == 4:\n",
    "                return convert_date_format(f'Dec 31, {aired[aired.find(\"to\")+3:]}')\n",
    "            if len(aired) == 9:\n",
    "                partial_date = aired.replace('to','').rstrip().lstrip()\n",
    "                return convert_date_format(f'{partial_date[:3]} 1, {partial_date[5:]}')\n",
    "\n",
    "        else:\n",
    "            return convert_date_format(aired)\n",
    "\n",
    "    \n",
    "def calculate_airing_duration(df_row):\n",
    "    if df_row['details.Aired'] == 'Not available':\n",
    "        return None\n",
    "    \n",
    "    from_date = df_row['aired_from']\n",
    "    to_date = df_row['aired_to']\n",
    "    \n",
    "    if to_date is None and df_row['details.Status'] == 'Currently Airing':\n",
    "        to_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    try:\n",
    "        from_datetime = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        to_datetime = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "    except:\n",
    "        return 0\n",
    "    else:\n",
    "        return int((to_datetime - from_datetime).total_seconds() / 86400)\n",
    "\n",
    "\n",
    "def get_hours_per_episode(df_row):\n",
    "    if 'hr' in df_row['details.Duration']:\n",
    "        return int(df_row['details.Duration'][:df_row['details.Duration'].find('hr')-1])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_minutes_per_episode(df_row):\n",
    "    if 'min' in df_row['details.Duration']:\n",
    "        if 'hr.' in df_row['details.Duration']:\n",
    "            return int(df_row['details.Duration'][df_row['details.Duration'].find('hr.')+4:df_row['details.Duration'].find('min')-1])\n",
    "        else:\n",
    "            return int(df_row['details.Duration'][:df_row['details.Duration'].find('min')-1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def get_seconds_per_episode(df_row):\n",
    "    if 'sec' in df_row['details.Duration']:\n",
    "        return int(df_row['details.Duration'][:df_row['details.Duration'].find('sec')-1])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def calculate_episode_lenght_in_seconds(df_row):\n",
    "    return df_row['hours_per_episode']*3600 + df_row['minutes_per_episode']*60 + df_row['seconds_per_episode']\n",
    "    \n",
    "\n",
    "def calculate_airing_duration_in_seconds(df_row):\n",
    "    if df_row['details.Aired'] == 'Not available':\n",
    "        return None\n",
    "    \n",
    "    if df_row['details.Episodes'] != 'Unknown':\n",
    "        return int(df_row['details.Episodes']) * df_row['episode_lenght_in_seconds']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def fix_episodes(df_row): \n",
    "    if df_row['details.Episodes'] != 'Unknown':\n",
    "        return int(df_row['details.Episodes'])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "composite-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aired_from'] = df.apply(get_aired_from_date,axis=1)\n",
    "df['aired_to'] = df.apply(get_aired_to_date,axis=1)\n",
    "df['days_in_air'] = df.apply(calculate_airing_duration,axis=1)\n",
    "df['hours_per_episode'] = df.apply(get_hours_per_episode,axis=1)\n",
    "df['minutes_per_episode'] = df.apply(get_minutes_per_episode,axis=1)\n",
    "df['seconds_per_episode'] = df.apply(get_seconds_per_episode,axis=1)\n",
    "df['episode_lenght_in_seconds'] = df.apply(calculate_episode_lenght_in_seconds,axis=1)\n",
    "df['seconds_in_air'] = df.apply(calculate_airing_duration_in_seconds,axis=1)\n",
    "df['details.Episodes'] = df.apply(fix_episodes,axis=1)\n",
    "df['aired_from'] = pd.to_datetime(df['aired_from'])\n",
    "df['aired_to'] = pd.to_datetime(df['aired_to'])\n",
    "df['details.Producers'] = df['details.Producers'].astype(str)\n",
    "df['details.Studios'] = df['details.Studios'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectible-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(path='../datasets/anime/enhanced_data/prepared_animes.parquet')\n",
    "df.to_csv('../datasets/anime/enhanced_data/prepared_animes.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "strong-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list_in_column(data_dict,column_for_parse):\n",
    "    result_list = []\n",
    "    for obj in data_dict:\n",
    "        for value in obj['details'][column_for_parse]:\n",
    "            result_list.append(value)\n",
    "\n",
    "    return list(set(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "senior-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatened 517 json files into one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-e32e8de91f77>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_df[genre] = genre_df.apply(create_genre_column,axis=1)\n"
     ]
    }
   ],
   "source": [
    "animes_dict = concatened_json_files('../datasets/anime/raw_data/')\n",
    "genre_df = df[['id','details.Genres']]\n",
    "\n",
    "for genre in parse_list_in_column(animes_dict,'Genres'):\n",
    "    def create_genre_column(df_row):\n",
    "        if genre in df_row['details.Genres']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    genre_df[genre] = genre_df.apply(create_genre_column,axis=1)\n",
    "\n",
    "genre_df.to_parquet(path='../datasets/anime/enhanced_data/animes_genres.parquet')\n",
    "genre_df.to_csv('../datasets/anime/enhanced_data/animes_genres.csv',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
